import google.generativeai as genai
from google.generativeai import types
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI()

# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
# API_KEY = os.getenv("GEMINI_API_KEY")
API_KEY =
if not API_KEY:
    raise Exception("GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")


# client = genai.Client(api_key=API_KEY)
# API í‚¤ë¡œ Gemini ì„¤ì •
genai.configure(api_key=API_KEY)


# ìš”ì²­ ë°ì´í„° ëª¨ë¸ ì •ì˜
class PromptRequest(BaseModel):
    prompt: str

# ì‚¬ìš©í•  Gemini ëª¨ë¸ ì„¤ì •
# GenerationConfigë¥¼ í†µí•´ ëª¨ë¸ì˜ ë™ì‘ì„ ì„¸ë¶€ì ìœ¼ë¡œ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
generation_config_dict  = {
  "temperature": 0.7,
  "max_output_tokens": 8192, # ëª¨ë¸ì— ë”°ë¼ ìµœëŒ€ê°’ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
}
generation_config = types.GenerationConfig(**generation_config_dict)

# ëª¨ë¸ ì´ˆê¸°í™” ì‹œ ë³€í™˜ëœ ê°ì²´ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    generation_config=generation_config, # âœ… íƒ€ì…ì´ ë§ëŠ” ê°ì²´ë¥¼ ì „ë‹¬
    system_instruction="You are a helpful assistant.",
)


# FastAPI ì—”ë“œí¬ì¸íŠ¸ ì •ì˜
@app.post("/api/chatbot")
async def generate_response_endpoint(request: PromptRequest):
    try:
        # âœ… ìˆ˜ì •ëœ ëª¨ë¸ í˜¸ì¶œ ë°©ì‹
        response = model.generate_content(request.prompt)
        # ----- ğŸ‘‡ ë””ë²„ê¹…ì„ ìœ„í•œ ì½”ë“œ ì¶”ê°€ -----
        print("--- Full Gemini Response ---")
        print(response)
        print("--------------------------")
        # ------------------------------------

        # ì‘ë‹µì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ë¹„ì–´ìˆë‹¤ë©´ ì°¨ë‹¨ ì´ìœ ë¥¼ í™•ì¸
        if not response.parts:
            # response.prompt_feedback ì—ì„œ ì°¨ë‹¨ ì´ìœ ë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            block_reason = response.prompt_feedback.block_reason
            print(f"Response was blocked. Reason: {block_reason}")
            # í´ë¼ì´ì–¸íŠ¸ì—ê²Œë„ ì°¨ë‹¨ ì‚¬ì‹¤ì„ ì•Œë ¤ì£¼ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
            raise HTTPException(status_code=400, detail=f"Response blocked by safety filters: {block_reason}")

        return {"response": response.text}

    except HTTPException as http_exc:
        # ì´ë¯¸ ì²˜ë¦¬ëœ HTTP ì˜ˆì™¸ëŠ” ë‹¤ì‹œ ë°œìƒì‹œí‚µë‹ˆë‹¤.
        raise http_exc

    except Exception as e:
        # ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´ ì„œë²„ ë¡œê·¸ì— ìì„¸í•œ ë‚´ìš©ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
        print(f"Error calling Gemini API: {e}")
        raise HTTPException(status_code=500, detail=f"Error calling Gemini API: {e}")

# # Gemini API í˜¸ì¶œ í•¨ìˆ˜
# def gemini_response(prompt: str) -> str:
#     response = client.models.generate_content(
#         model="gemini-1.5-flash",
#         contents=prompt,
#         config=types.GenerateContentConfig(
#             system_instruction="You are a helpful assistant.",
#             max_output_tokens=10000,
#             temperature=0.7,
#         ),
#     )
#     return response.text
#
# # FastAPI ì—”ë“œí¬ì¸íŠ¸ ì •ì˜
# @app.post("/api/generate-response")
# async def generate_response_endpoint(request: PromptRequest):
#     try:
#         response_text = gemini_response(request.prompt)
#         return {"response": response_text}
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=f"Error calling Gemini API: {e}")
